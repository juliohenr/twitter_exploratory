{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sending GET requests from the API\n",
    "import requests\n",
    "# For saving access tokens and for file management when creating and adding to the dataset\n",
    "import os\n",
    "# For dealing with json responses we receive from the API\n",
    "import json\n",
    "# For displaying the data after\n",
    "import pandas as pd\n",
    "# For saving the response data in CSV format\n",
    "import csv\n",
    "# For parsing the dates received from twitter in readable formats\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "#To add wait time between requests\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "from unicodedata import normalize as norm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1466874887524421632</td>\n",
       "      <td>2.230226e+09</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>2021-12-04T23:05:28.000Z</td>\n",
       "      <td>1130648708566179841</td>\n",
       "      <td>1467268847745081346</td>\n",
       "      <td>@UniversalPicsBr @anygabrielly @Fiuk quero tan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1467268691884654595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>2021-12-04T23:04:51.000Z</td>\n",
       "      <td>1355987894603837442</td>\n",
       "      <td>1467268691884654595</td>\n",
       "      <td>Tata Werneck dá show de maturidade e pede fim ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1467249854728609797</td>\n",
       "      <td>1.441891e+18</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>2021-12-04T23:03:56.000Z</td>\n",
       "      <td>1465436751388885002</td>\n",
       "      <td>1467268463433560066</td>\n",
       "      <td>@Claudia77613373 @afazendarecord @dynhoalvesre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1467267671632887816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 3, 'like_c...</td>\n",
       "      <td>2021-12-04T23:00:48.000Z</td>\n",
       "      <td>185448711</td>\n",
       "      <td>1467267671632887816</td>\n",
       "      <td>Eu e mainha botamos o lady night com Fiuk aqui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1467132306989191168</td>\n",
       "      <td>1.418676e+18</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 1, 'like_c...</td>\n",
       "      <td>2021-12-04T22:59:40.000Z</td>\n",
       "      <td>1081607577778225153</td>\n",
       "      <td>1467267388383109120</td>\n",
       "      <td>@yaeminion Alguem me explicar por que o Fiuk é...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       conversation_id  in_reply_to_user_id  \\\n",
       "0  1466874887524421632         2.230226e+09   \n",
       "1  1467268691884654595                  NaN   \n",
       "2  1467249854728609797         1.441891e+18   \n",
       "3  1467267671632887816                  NaN   \n",
       "4  1467132306989191168         1.418676e+18   \n",
       "\n",
       "                                      public_metrics  \\\n",
       "0  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "1  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "2  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "3  {'retweet_count': 0, 'reply_count': 3, 'like_c...   \n",
       "4  {'retweet_count': 0, 'reply_count': 1, 'like_c...   \n",
       "\n",
       "                 created_at            author_id                   id  \\\n",
       "0  2021-12-04T23:05:28.000Z  1130648708566179841  1467268847745081346   \n",
       "1  2021-12-04T23:04:51.000Z  1355987894603837442  1467268691884654595   \n",
       "2  2021-12-04T23:03:56.000Z  1465436751388885002  1467268463433560066   \n",
       "3  2021-12-04T23:00:48.000Z            185448711  1467267671632887816   \n",
       "4  2021-12-04T22:59:40.000Z  1081607577778225153  1467267388383109120   \n",
       "\n",
       "                                                text  \n",
       "0  @UniversalPicsBr @anygabrielly @Fiuk quero tan...  \n",
       "1  Tata Werneck dá show de maturidade e pede fim ...  \n",
       "2  @Claudia77613373 @afazendarecord @dynhoalvesre...  \n",
       "3  Eu e mainha botamos o lady night com Fiuk aqui...  \n",
       "4  @yaeminion Alguem me explicar por que o Fiuk é...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets = pd.read_csv(\"df_tweets.csv\")\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now = 2021-12-19 17:17:54.049865\n",
      "date and time = 2021-12-19T17:17:54.000Z\n",
      "date and time = 2021-12-14T17:17:54.000Z\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.utcnow()\n",
    " \n",
    "print(\"now =\", now)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "print(\"date and time =\", dt_string)\n",
    "\n",
    "    \n",
    "d = now - timedelta(days=5)\n",
    "\n",
    "dt_string2 = d.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 12, 19, 12, 25, 25, 837020)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.utcnow() - timedelta(hours=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_tweets[\"created_at\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words_domain=[\"não\",\"da\",\"globoplay\",\n",
    "                    \"só\",\"pra\",\"vc\",\"pois\",\"lá\",\"outro\",\n",
    "                    \"outra\",\"vou\",\"vão\",\"assim\",\"outro\",\n",
    "                    \"outra\",\"ter\",\"ver\",\"agora\",\"hoje\",\n",
    "                    \"tudo\",\"todos\",\"todo\",\"ah\",\"acho\",\n",
    "                    \"achamos\",\"né\",\"ser\",\"vai\",\"alguma\",\n",
    "                    \"mas\",\"porém\",\"entretanto\",\n",
    "                    \"faz\",\"fazemos\",\"farão\",\n",
    "                    \"tbm\",\"fazia\",\"tá\",\"tb\",\"ia\",\n",
    "                    \"ir\",\"to\",\"nela\",\"nele\",\"nelas\",\n",
    "                    \"neles\",\"naquele\",\"naquueles\",\n",
    "                    \"naquelas\",\"naquela\",\"coisa\",\"mim\",\n",
    "                    \"tô\",\"aí\",\"n\",\n",
    "                    \"pro\",\"é\",\"dessa\",\"vamos\",\"q\",\n",
    "                    \"desse\",\"tava\",\"msm\",\"vamo\",\"que\",\"porque\",\n",
    "                    \"nem\",\"mano\",\"manos\",\"caras\",\"xd\",\"kkkk\",\"pq\",\"por\",\"cara\",\n",
    "                    \"gente\",\"dar\",\"sobre\",\"tão\",\"toda\",\"vezes\",\n",
    "                    \"então\",\"viu\",\"vemos\",\"pode\",\"podemos\",\"vez\",\n",
    "                    \"vcs\",\"hein\",\"quer\",\"sim\",\"deu\",\"já\",\"demos\",\n",
    "                    \"todas\",\"aqui\",\"sei\",\"sabemos\",\"fazer\",\"fiz\",\n",
    "                    \"fez\",\"fazemos\",\"vem\",\"vamos\",\"ainda\",\"tanto\",\"nesse\",\"pocah\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for exploratory analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_count_words(text_column=None,\n",
    "                         label_column=None,\n",
    "                         name_class=None,\n",
    "                         dataframe=None,\n",
    "                         metric='SUM',\n",
    "                         top=50,return_df=True):\n",
    "    \n",
    "    corpus = dataframe[text_column].values\n",
    "    \n",
    " \n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    data_vect = vectorizer.fit_transform(corpus)\n",
    "    data_vect = data_vect.toarray()\n",
    "    \n",
    "    print(vectorizer.get_feature_names())\n",
    "    \n",
    "    df_count_words =  pd.DataFrame({\n",
    "    \"WORDS\":vectorizer.get_feature_names() ,\n",
    "    \"MEAN\":data_vect.mean(axis=0),\n",
    "    \"SUM\":data_vect.sum(axis=0),\n",
    "    \"STD\":data_vect.std(axis=0),\n",
    "    }) \n",
    "    \n",
    "    \n",
    "\n",
    "    if return_df:\n",
    "    \n",
    "        return df_count_words[[metric,'WORDS']].sort_values(by=[metric],ascending=False)[0:top]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        \n",
    "        ax = sns.barplot(x=metric, \n",
    "                 y=\"WORDS\", \n",
    "                 data=df_count_words[[metric,'WORDS']].sort_values(by=[metric],\n",
    "                                                                            ascending=False)[0:top])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_text_to_no_repeat_words(text):\n",
    "\n",
    "    text_with_no_repeat_words = text.split(\" \")\n",
    "\n",
    "    text_with_no_repeat_words = [i for i in text_with_no_repeat_words if i!=\"\"]\n",
    "\n",
    "    text_with_no_repeat_words = set(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = list(text_with_no_repeat_words)\n",
    "\n",
    "    text_with_no_repeat_words = \" \".join(text_with_no_repeat_words)\n",
    "\n",
    "    return text_with_no_repeat_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(tweet):\n",
    "    \n",
    "    list_hashtags = re.findall(r\"#[a-zA-Zà-úÀ-Ú0-9]+\",tweet)\n",
    "    \n",
    "    string_only_hashtags = \" \".join(list_hashtags)\n",
    "    \n",
    "    return string_only_hashtags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_citation(tweet):\n",
    "    \n",
    "    list_hashtags = re.findall(r\"@[a-zA-Zà-úÀ-Ú0-9]+\",tweet)\n",
    "    \n",
    "    string_only_hashtags = \" \".join(list_hashtags)\n",
    "    \n",
    "    return string_only_hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to clean the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text,stop_words_domain =[]):\n",
    "\n",
    "    \n",
    "    nltk_stopwords =  stopwords.words('portuguese') + stop_words_domain\n",
    "\n",
    "    nltk_stopwords_processed = [norm('NFKD', i).encode('ascii', 'ignore').decode().lower() for i in nltk_stopwords]\n",
    "\n",
    "    regex_stop_words = '|'.join(nltk_stopwords)\n",
    "\n",
    "    \n",
    "    regex_remove_https = 'https([a-zA-Zà-úÀ-Ú0-9]|[-()\\#/@;:<>{}`+=~|.!?,])+'\n",
    "\n",
    "\n",
    "    text_without_https = re.sub(r\"(\\s|^){0}(\\s{0})*($|\\s)\".format(regex_remove_https),\" \",text)\n",
    "\n",
    "\n",
    "    text_without_special_caracteres = re.sub(r\"[^a-zA-ZÀ-Úà-ú]+\",\" \",text_without_https)\n",
    "\n",
    "    text_without_alone_caractere = re.sub(r\"\\s[a-zA-ZÀ-Úà-ú]\\s|\\s[a-zA-ZÀ-Úà-ú]$|^[a-zA-ZÀ-Úà-ú]\\s\",\" \",text_without_special_caracteres)\n",
    "    \n",
    "\n",
    "    text_pattern_space = re.sub(r\"\\s+\",\" \",text_without_alone_caractere)\n",
    "\n",
    "    \n",
    "    text_split = text_pattern_space.split(\" \")\n",
    "\n",
    "    \n",
    "    text_list = [i for i in text_split  if norm('NFKD', i).encode('ascii', 'ignore').decode().lower() not in nltk_stopwords_processed]\n",
    "\n",
    "\n",
    "    text_final = \" \".join(text_list)\n",
    "\n",
    "\n",
    "    return text_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs = plot_bar_count_words(text_column='text_clean',\n",
    "                                                dataframe=df_tweets,\n",
    "                                                metric='SUM',top=10,return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[\"text_clean\"] = df_tweets[\"text\"].apply(lambda x: text_cleaner(text = x,stop_words_domain=stop_words_domain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test get #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"duhudhuhd #tweet #tweet1 usuhsdsnsund #tweet2 jdisdisndsjdis #tweet3 ususjus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#tweet'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(\"#([a-zA-Zà-úÀ-Ú0-9]|[-()\\#/@;:<>{}`+=~|.!?,])+\",tweet).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#tweet', '#tweet1', '#tweet2', '#tweet3']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(?<![#@])\\b\\w+\\b\n",
    "\n",
    "re.findall(\"#[a-zA-Zà-úÀ-Ú0-9]+\",tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duhudhuhd   usuhsdsnsund  jdisdisndsjdis  ususjus'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"#[a-zA-Zà-úÀ-Ú0-9]+\",\"\",tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match(\"#([a-zA-Zà-úÀ-Ú0-9]|[-()\\#/@;:<>{}`+=~|.!?,])+\",tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[\"hashtags\"] = df_tweets[\"text\"].apply(lambda x: extract_hashtags(tweet = x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs = plot_bar_count_words(text_column='hashtags',\n",
    "                                                dataframe=df_tweets,\n",
    "                                                metric='SUM',top=50,return_df=True)\n",
    "df_report_sum_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs[\"WORDS\"] =  \"#\" + df_report_sum_docs[\"WORDS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[\"citations\"] = df_tweets[\"text\"].apply(lambda x: extract_citation(tweet = x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_sum_docs = plot_bar_count_words(text_column='citations',\n",
    "                                                dataframe=df_tweets,\n",
    "                                                metric='SUM',top=50,return_df=True)\n",
    "df_report_sum_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
